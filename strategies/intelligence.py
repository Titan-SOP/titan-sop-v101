# intelligence.py
# Titan SOP V58.0 - Intelligence Ingestor
# ä¿®æ­£é‡é»: 1. æ–°å¢ Gemini AI æ·±åº¦è§£æåŠŸèƒ½ã€‚ 2. [V58.0] æ–°å¢ Local Brain é—œéµå­—æ¯”å°å¼•æ“ä½œç‚ºå‚™æ´ã€‚

import re
import pdfplumber
from typing import Dict, List
import pandas as pd
from knowledge_base import TitanKnowledgeBase
from config import Config
import google.generativeai as genai

class IntelligenceIngestor:

    def __init__(self):
        self.bullish_keywords = ["æ“´ç”¢", "è³‡æœ¬æ”¯å‡º", "æ–°å» ", "ä¾›ä¸æ‡‰æ±‚", "æ¼²åƒ¹", "ä¸Šä¿®", "æ€¥å–®"]
        self.bearish_keywords = ["ä¸‹ä¿®", "åº«å­˜èª¿æ•´", "é€†é¢¨", "ä¸å¦‚é æœŸ", "ç å–®", "é™åƒ¹"]

    def _calculate_score(self, text: str) -> int:
        score = 0
        for k in self.bullish_keywords:
            if k in text: score += 10
        for k in self.bearish_keywords:
            if k in text: score -= 10
        return score

    def _local_brain_analysis(self, text: str, kb: TitanKnowledgeBase, df: pd.DataFrame) -> str:
        """[V58.0] SOP é—œéµå­—æ¯”å°å¼•æ“ (Local Brain)"""
        report = "### ğŸ§  **SOP æœ¬åœ°å¤§è…¦åˆ†æ**\n\n"
        
        # 1. æƒæç™¼å‚µæ•…äº‹é—œéµå­—
        found_story_keywords = [k for k in Config.STORY_KEYWORDS if k in text]
        if found_story_keywords:
            report += f"#### ğŸ“„ å ±å‘Šé‡é» (ç™¼å‚µæ•…äº‹)\n- å‘½ä¸­é—œéµå­—: **{', '.join(found_story_keywords)}**\n"
        else:
            report += "#### ğŸ“„ å ±å‘Šé‡é» (ç™¼å‚µæ•…äº‹)\n- æœªç›´æ¥å‘½ä¸­æ ¸å¿ƒç™¼å‚µæ•…äº‹é—œéµå­—ã€‚\n"

        # 2. æƒææ—ç¾¤é—œéµå­—ä¸¦æ‰¾å‡ºé—œè¯æ¨™çš„
        report += "\n#### ğŸ¯ SOP é—œè¯æ¨™çš„\n"
        found_stocks = set()
        for sector, stocks in kb.sector_bellwether_map.items():
            if sector in text:
                for stock_identifier in stocks:
                    if not df.empty:
                        match = df[df['stock_code'].str.contains(stock_identifier, na=False) | df['name'].str.contains(stock_identifier, na=False)]
                        if not match.empty:
                            for _, row in match.iterrows():
                                found_stocks.add(f"{row['name']} ({row['stock_code']})")
        
        if found_stocks:
            for stock in sorted(list(found_stocks)):
                report += f"- `{stock}` (é—œè¯æ—ç¾¤)\n"
        else:
            report += "- æœªåœ¨æ‚¨çš„ CB æ¸…å–®ä¸­æ‰¾åˆ°èˆ‡å ±å‘Šç›¸é—œçš„æ—ç¾¤æ¨™çš„ã€‚\n"
            
        return report

    def analyze_file(self, uploaded_file, kb: TitanKnowledgeBase, df: pd.DataFrame) -> Dict:
        """é€šç”¨æª”æ¡ˆåˆ†æå…¥å£ (æ”¯æ´å…¨æ ¼å¼)"""
        fname = uploaded_file.name.lower()
        text = ""
        try:
            if fname.endswith('.pdf'):
                with pdfplumber.open(uploaded_file) as pdf:
                    for page in pdf.pages:
                        text += page.extract_text() or ""
            elif fname.endswith('.txt') or 'gmail' in fname:
                text = uploaded_file.getvalue().decode("utf-8")
            elif fname.endswith(('.png', '.jpg', '.jpeg')):
                return self._analyze_image(uploaded_file)
            elif fname.endswith(('.mp3', '.wav', '.mp4', '.m4a')):
                return self._analyze_media(uploaded_file)
            else:
                return {"error": f"å°šæœªæ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {fname}"}

            local_report = self._local_brain_analysis(text, kb, df)
            
            return {
                "type": "æ–‡ä»¶" if fname.endswith(('.pdf', '.txt')) else "éƒµä»¶",
                "summary": text[:500] + "...",
                "full_text": text,
                "local_analysis_md": local_report
            }

        except Exception as e:
            return {"error": f"æª”æ¡ˆè®€å–æˆ–åˆ†æå¤±æ•—: {str(e)}"}

    def analyze_with_gemini(self, file_content_text: str) -> str:
        """[V50.0] ä½¿ç”¨ Gemini AI é€²è¡Œæ·±åº¦è§£æ"""
        try:
            model = genai.GenerativeModel('gemini-pro')
            prompt = f"""
            ä½ æ˜¯ä¸€ä½é ‚å°–çš„å¯è½‰å‚µï¼ˆCBï¼‰é‡‘èåˆ†æå¸«ï¼Œç†Ÿæ‚‰é„­æ€ç¿°çš„æ³¢æ®µæŠ•è³‡ç­–ç•¥ã€‚
            è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„æ–‡ä»¶å…§å®¹ï¼Œä¾æ“šé„­æ€ç¿°çš„é‚è¼¯é€²è¡Œåˆ†æï¼š

            1.  **æ‘˜è¦é‡é»**ï¼šç¸½çµæ–‡ä»¶æ ¸å¿ƒè§€é»ï¼Œä¸è¶…é 150 å­—ã€‚
            2.  **ç™¼å‚µæ•…äº‹æ¯”å°**ï¼šåˆ¤æ–·å…§å®¹æ˜¯å¦æåŠä»»ä½•æ½›åœ¨çš„ã€Œç™¼å‚µæ•…äº‹ã€ã€‚è«‹ç›´æ¥æ¯”å°é„­æ€ç¿°çš„æ ¸å¿ƒé—œéµå­—ï¼Œä¾‹å¦‚ï¼šã€Œæ“´ç”¢ã€ã€ã€Œè³‡æœ¬æ”¯å‡ºã€ã€ã€Œæ–°å» ã€ã€ã€Œä½µè³¼ã€ã€ã€Œè½‰æ©Ÿã€ã€ã€Œç‡Ÿæ”¶çˆ†ç™¼ã€ã€ã€Œå¾ç„¡åˆ°æœ‰ã€ã€ã€Œæ”¿ç­–äº‹ä»¶ã€ã€‚è‹¥æœ‰ï¼Œè«‹ç›´æ¥å¼•ç”¨åŸæ–‡å¥å­ã€‚
            3.  **å¤šç©ºåˆ¤æ–·**ï¼šåŸºæ–¼æ–‡ä»¶å…§å®¹ï¼Œçµ¦å‡ºå°ç›¸é—œå…¬å¸æˆ–ç”¢æ¥­çš„ã€ŒğŸ”¥ æ¨‚è§€ã€ã€ã€Œâ„ï¸ æ‚²è§€ã€æˆ–ã€ŒğŸ˜ ä¸­æ€§ã€çœ‹æ³•ï¼Œä¸¦ç°¡è¿°ç†ç”±ã€‚
            4.  **ç›¸é—œå°è‚¡æ¨™çš„**ï¼šæ˜ç¢ºåˆ—å‡ºæ–‡ä»¶ä¸­æåŠçš„æ‰€æœ‰ã€Œå°è‚¡ä»£è™Ÿã€ï¼ˆå››ä½æ•¸ä»£ç¢¼ï¼‰èˆ‡å…¶å…¬å¸åç¨±ã€‚

            --- æ–‡ä»¶å…§å®¹é–‹å§‹ ---
            {file_content_text[:8000]}
            --- æ–‡ä»¶å…§å®¹çµæŸ ---

            è«‹ä»¥ Markdown æ ¼å¼æ¢åˆ—å¼å›è¦†ä½ çš„åˆ†æå ±å‘Šã€‚
            """
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"âŒ **Gemini AI åˆ†æå¤±æ•—**\néŒ¯èª¤è¨Šæ¯: {str(e)}\nè«‹æª¢æŸ¥æ‚¨çš„ API Key æ˜¯å¦æ­£ç¢ºæˆ–ç¶²è·¯é€£ç·šæ˜¯å¦æ­£å¸¸ã€‚"

    def _analyze_image(self, file) -> Dict:
        return {
            "type": "Image (åœ–æª”)", "status": "å·²æ¥æ”¶ (å¾…ä¸²æ¥ GPT-4 Vision)", "score": 0,
            "summary": f"æ”¶åˆ°åœ–ç‰‡: {file.name}ï¼Œæ­£åœ¨é€²è¡Œ OCR èˆ‡åœ–è¡¨åˆ†æ..."
        }

    def _analyze_media(self, file) -> Dict:
        return {
            "type": "Media (å½±éŸ³)", "status": "å·²æ¥æ”¶ (å¾…ä¸²æ¥ Whisper STT)", "score": 0,
            "summary": f"æ”¶åˆ°å½±éŸ³æª”: {file.name}ï¼Œæ­£åœ¨è½‰éŒ„é€å­—ç¨¿..."
        }